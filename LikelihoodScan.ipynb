{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from coffea import util, hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nJets = 4\n",
    "\n",
    "outputMC = util.load(f'Outputs/outputMCOther_ttgamma_condorFull_{nJets}jet.coffea')\n",
    "outputMC.add(util.load(f'Outputs/outputMCSingletop_ttgamma_condorFull_{nJets}jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCTTbar1l_ttgamma_condorFull_{nJets}jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCTTbar2l_ttgamma_condorFull_{nJets}jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCTTGamma_ttgamma_condorFull_{nJets}jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCWJets_ttgamma_condorFull_{nJets}jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCZJets_ttgamma_condorFull_{nJets}jet.coffea'))\n",
    "\n",
    "outputData = util.load(f'Outputs/outputData_ttgamma_condorFull_{nJets}jet.coffea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping= {'ttgamma': ['TTGamma_Dilepton','TTGamma_SingleLept','TTGamma_Hadronic'],\n",
    "           'ttbar'  : ['TTbarPowheg_Dilepton', 'TTbarPowheg_Semilept', 'TTbarPowheg_Hadronic'],\n",
    "           'Single top':['ST_s_channel', 'ST_tW_channel', 'ST_tbarW_channel', 'ST_tbar_channel', 'ST_t_channel'],\n",
    "           'Wgamma' : ['WGamma_01J_5f'],\n",
    "           'Zgamma' : ['ZGamma_01J_5f_lowMass'],\n",
    "           'Other'    : ['TTWtoLNu','TTWtoQQ','TTZtoLL','W1jets', 'W2jets', 'W3jets', 'W4jets','DYjetsM10to50', 'DYjetsM50','GJets_HT40To100', 'GJets_HT100To200', 'GJets_HT200To400', 'GJets_HT400To600', 'GJets_HT600ToInf', 'QCD_Pt20to30_Ele', 'QCD_Pt30to50_Ele', 'QCD_Pt50to80_Ele', 'QCD_Pt80to120_Ele', 'QCD_Pt120to170_Ele', 'QCD_Pt170to300_Ele', 'QCD_Pt300toInf_Ele', 'QCD_Pt20to30_Mu', 'QCD_Pt30to50_Mu', 'QCD_Pt50to80_Mu', 'QCD_Pt80to120_Mu', 'QCD_Pt120to170_Mu', 'QCD_Pt170to300_Mu', 'QCD_Pt300to470_Mu', 'QCD_Pt470to600_Mu', 'QCD_Pt600to800_Mu', 'QCD_Pt800to1000_Mu', 'QCD_Pt1000toInf_Mu']\n",
    "          }\n",
    "\n",
    "groupingPho= {\"Genuine\":slice(1,2),\n",
    "              \"MisIDele\": slice(2,3),\n",
    "              \"NonPrompt\":slice(3,5),\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MisIDSFResults = {'FSRDown': 2.3258888950981658,\n",
    " 'FSRUp': 2.323321648572707,\n",
    " 'ISRDown': 2.3230711845246037,\n",
    " 'ISRUp': 2.3250742760361485,\n",
    " 'JERDown': 2.4916358829485334,\n",
    " 'JERUp': 2.1624914842453293,\n",
    " 'JESDown': 2.509294663019229,\n",
    " 'JESUp': 2.135357294316598,\n",
    " 'PDFDown': 2.324502013792059,\n",
    " 'PDFUp': 2.323545650509748,\n",
    " 'Q2ScaleDown': 2.3293301438482605,\n",
    " 'Q2ScaleUp': 2.3167686733720436,\n",
    " 'btagWeight_heavyDown': 2.3161258587737783,\n",
    " 'btagWeight_heavyUp': 2.3318748601639374,\n",
    " 'btagWeight_lightDown': 2.314511973536161,\n",
    " 'btagWeight_lightUp': 2.33352399467015,\n",
    " 'eleEffWeightDown': 2.3554278067205736,\n",
    " 'eleEffWeightUp': 2.2932330953488718,\n",
    " 'muEffWeightDown': 2.3240404881606733,\n",
    " 'muEffWeightUp': 2.3240404881606733,\n",
    " 'nominal': 2.3240404882109207,\n",
    " 'puWeightDown': 2.5637652930311705,\n",
    " 'puWeightUp': 2.1120559976304656}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photonPurityResults = {'FSRDown': (0.8030142091355378, 0.02656639631207204),\n",
    " 'FSRUp': (0.803467537651622, 0.02629404549365212),\n",
    " 'ISRDown': (0.8018302949232643, 0.026126375541722265),\n",
    " 'ISRUp': (0.804461717954526, 0.026444066165957382),\n",
    " 'JERDown': (0.8051019088926759, 0.026506921728798816),\n",
    " 'JERUp': (0.7984673072982711, 0.026222706737238234),\n",
    " 'JESDown': (0.8060810360464794, 0.026711459939952456),\n",
    " 'JESUp': (0.8002546049275313, 0.026059478589156537),\n",
    " 'PDFDown': (0.8035204920374956, 0.02653775791567313),\n",
    " 'PDFUp': (0.8035307005167678, 0.026281259025561554),\n",
    " 'Q2ScaleDown': (0.8043317356519103, 0.027877124454999947),\n",
    " 'Q2ScaleUp': (0.8020354226529646, 0.024999047555065074),\n",
    " 'btagWeight_heavyDown': (0.8032875411324775, 0.026463296023541468),\n",
    " 'btagWeight_heavyUp': (0.8035893554441516, 0.026337141144431832),\n",
    " 'btagWeight_lightDown': (0.8034995393387975, 0.02643523179281183),\n",
    " 'btagWeight_lightUp': (0.8033743258917129, 0.02636304397032702),\n",
    " 'eleEffWeightDown': (0.803453136283781, 0.026436277365020047),\n",
    " 'eleEffWeightUp': (0.8034205363035585, 0.026361799486459368),\n",
    " 'muEffWeightDown': (0.8034257479581941, 0.026434470425939233),\n",
    " 'muEffWeightUp': (0.8034475206831849, 0.026363581517734703),\n",
    " 'nominal': (0.8034366347463864, 0.02639897109376131),\n",
    " 'puWeightDown': (0.8079974209720092, 0.026502251190634044),\n",
    " 'puWeightUp': (0.798484309778782, 0.026287794984425114)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topPurityResults = {'FSRDown': (0.7625088925186997, 0.054231604484011736),\n",
    " 'FSRUp': (0.7696066723943817, 0.05814402063353581),\n",
    " 'ISRDown': (0.822724047640092, 0.05839679242422305),\n",
    " 'ISRUp': (0.7238656927125936, 0.05548770340953093),\n",
    " 'JERDown': (0.7693957648855223, 0.05317617974697675),\n",
    " 'JERUp': (0.7478146052911734, 0.05722566554922455),\n",
    " 'JESDown': (0.7945911123489572, 0.054569995530775676),\n",
    " 'JESUp': (0.7141144449951271, 0.057289368764441906),\n",
    " 'PDFDown': (0.7657202166884056, 0.05667093455148253),\n",
    " 'PDFUp': (0.7662539910761348, 0.0562304496271842),\n",
    " 'Q2ScaleDown': (0.7597117742552794, 0.0593452338480461),\n",
    " 'Q2ScaleUp': (0.7762575130283725, 0.053551073218728366),\n",
    " 'btagWeight_heavyDown': (0.7644770428104973, 0.056805065916077514),\n",
    " 'btagWeight_heavyUp': (0.7665034940652995, 0.05609976526397491),\n",
    " 'btagWeight_lightDown': (0.7630598879751872, 0.05654260955900684),\n",
    " 'btagWeight_lightUp': (0.7681546197410744, 0.056333544349048054),\n",
    " 'eleEffWeightDown': (0.7651281095045667, 0.05656284797091966),\n",
    " 'eleEffWeightUp': (0.7658846670114646, 0.05633446162264847),\n",
    " 'muEffWeightDown': (0.7652624114194411, 0.05653088379696748),\n",
    " 'muEffWeightUp': (0.7657516385354254, 0.056366155471439895),\n",
    " 'nominal': (0.7655058238808953, 0.05644847783453547),\n",
    " 'puWeightDown': (0.7559069098357679, 0.05526018303340832),\n",
    " 'puWeightUp': (0.7783595397212802, 0.05774640772959691)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = outputMC['M3'].sum('lepFlavor').sum('M3').group('dataset',hist.Cat(r'dataset',r'Samples',sorting='placement'),grouping)\n",
    "h = h.group('category',hist.Cat(r'category',r'Category',sorting='placement'),groupingPho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hData = outputData['M3'].sum('lepFlavor').sum('M3').sum('dataset').sum('category')\n",
    "nData = hData.values()[('noweight',)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPseudoData(mcYield, mcYieldErr, ttgammaSF=1., npSF=1., asimov=False):\n",
    "    mcYieldTest = mcYield.copy()\n",
    "    mcYieldTest[0] *=  ttgammaSF\n",
    "    mcYieldTest[:,2] *= npSF\n",
    "    \n",
    "    if not asimov:\n",
    "        mcYieldTest = np.random.poisson(mcYieldTest)\n",
    "\n",
    "    photonPurity = mcYieldTest[:,:2].sum()/mcYieldTest.sum()\n",
    "    photonPurityErr = 0.04\n",
    "\n",
    "    topPurity = mcYieldTest[:2].sum()/mcYieldTest.sum()\n",
    "    topPurityErr = 0.02\n",
    "\n",
    "    nData = mcYieldTest.sum()\n",
    "\n",
    "    return photonPurity, photonPurityErr, topPurity, topPurityErr, nData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numba\n",
    "\n",
    "def likelihoodFunction(ttgammaSF=1., nonPromptSF=1., mcValues=None, mcValuesErr=None, photonPurity=None, topPurity=None, nData = None, photonPurityErr=None, topPurityErr=None):\n",
    "    mcValues[0] *= ttgammaSF\n",
    "    mcValuesErr[0] *= ttgammaSF\n",
    "\n",
    "    mcValues[:,-1] *= nonPromptSF\n",
    "    mcValuesErr[:,-1] *= nonPromptSF\n",
    "    \n",
    "    nMC = mcValues.sum()\n",
    "    nMCErr = (mcValuesErr**2).sum()**0.5\n",
    "\n",
    "    #nIso is the sum of the first two columsn of data (genuine and misID)\n",
    "    nIso = mcValues[:,0:2].sum()\n",
    "    nIsoErr = (mcValuesErr[:,0:2]**2).sum()**0.5\n",
    "\n",
    "    #nTop is the sum of the first two rows (ttgamma and ttbar)\n",
    "    nTop = mcValues[0:2].sum()\n",
    "    nTopErr = (mcValuesErr[0:2]**2).sum()**0.5\n",
    "\n",
    "    mcPhotonPurity    = nIso/nMC\n",
    "    mcPhotonPurityErr = (mcPhotonPurity) * ((nIsoErr/nIso)**2 + (nMCErr/nMC)**2)**0.5\n",
    "\n",
    "    mcTopPurity = nTop/nMC\n",
    "    mcTopPurityErr = mcTopPurity * ((nTopErr/nTop)**2 + (nMCErr/nMC)**2)**0.5\n",
    "    \n",
    "    \n",
    "    chi2 = ((photonPurity-mcPhotonPurity)**2/(photonPurityErr**2 + mcPhotonPurityErr**2) + \n",
    "            (topPurity - mcTopPurity)**2/(topPurityErr**2 + mcTopPurityErr**2) +\n",
    "            (nData - nMC)**2/(nData + nMCErr**2)\n",
    "           )\n",
    "    \n",
    "    return np.exp(-0.5*chi2)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximizeLikelihood(fitData, \n",
    "                       ttgSF = None, nonPromptSF=None, \n",
    "                       startTTGamma = 1., startNonprompt = 1., \n",
    "                       nSteps = 100,\n",
    "                       verbose=False, \n",
    "                       find1sigma = False, \n",
    "                       nStepsErr = 20):\n",
    "\n",
    "\n",
    "    mcYield=fitData['mcYield']\n",
    "    mcYieldErr=fitData['mcYieldErr']\n",
    "    photonPurity=fitData['photonPurity']\n",
    "    photonPurityErr=fitData['photonPurityErr']\n",
    "    topPurity=fitData['topPurity']\n",
    "    topPurityErr=fitData['topPurityErr']\n",
    "    nData=fitData['nData']\n",
    "    \n",
    "    \n",
    "    if ttgSF is None:\n",
    "        ttgSF=startTTGamma\n",
    "        iTTGSteps = range(3)\n",
    "    else:\n",
    "        iTTGSteps = [1]\n",
    "\n",
    "    if nonPromptSF is None:\n",
    "        nonPromptSF=startNonprompt\n",
    "        iNPSteps = range(3)\n",
    "    else:\n",
    "        iNPSteps = [1]\n",
    "        \n",
    "    stepSize = 0.1\n",
    "    \n",
    "    lastStepLk = -1.\n",
    "\n",
    "    for steps in range(nSteps):\n",
    "\n",
    "        best_lk = -1\n",
    "        best_iTTG = -1\n",
    "        best_iNP = -1\n",
    "        \n",
    "        for iTTG in iTTGSteps:\n",
    "            for iNP in iNPSteps:\n",
    "                lk = likelihoodFunction(ttgammaSF = ttgSF + (iTTG-1)*stepSize , \n",
    "                                        nonPromptSF=nonPromptSF + (iNP-1)*stepSize, \n",
    "                                        mcValues=mcYield.copy(), mcValuesErr=mcYieldErr.copy(),\n",
    "                                        photonPurity=photonPurity, topPurity=topPurity, \n",
    "                                        photonPurityErr=photonPurityErr, topPurityErr=topPurityErr, \n",
    "                                        nData=nData)\n",
    "\n",
    "                if lk > best_lk:\n",
    "                    best_lk = lk\n",
    "                    best_iTTG = iTTG\n",
    "                    best_iNP = iNP\n",
    "\n",
    "        ttgSF = ttgSF+(best_iTTG-1)*stepSize\n",
    "        nonPromptSF = nonPromptSF + (best_iNP-1)*stepSize\n",
    "\n",
    "        if best_iTTG==best_iNP==1:\n",
    "            stepSize = stepSize/2.\n",
    "            lastStepLk=-1.\n",
    "\n",
    "        if verbose:\n",
    "            print(steps, ttgSF, nonPromptSF, stepSize, best_lk)\n",
    "            \n",
    "    if find1sigma:\n",
    "\n",
    "        ### scan for ttgSF down\n",
    "        ttgammaErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = ttgSF - ttgammaErr, \n",
    "                                         nonPromptSF=None, \n",
    "                                         nSteps = 50,\n",
    "                                    )\n",
    "\n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr -= stepSize\n",
    "                trend=-1\n",
    "        ttgammaDown = -1*ttgammaErr\n",
    "\n",
    "        ### scan for ttgSF up\n",
    "        ttgammaErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = ttgSF + ttgammaErr, \n",
    "                                         nonPromptSF=None, \n",
    "                                         nSteps = 50,\n",
    "                                        )\n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr -= stepSize\n",
    "                trend=-1\n",
    "        ttgammaUp = ttgammaErr\n",
    "\n",
    "        ### scan for npSF down\n",
    "        npErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = None, \n",
    "                                         nonPromptSF=nonPromptSF - npErr, \n",
    "                                         nSteps = 50,\n",
    "                                        )            \n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                npErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                npErr -= stepSize\n",
    "                trend=-1\n",
    "        nonPromptDown = -1*npErr\n",
    "\n",
    "        ### scan for npSF up        \n",
    "        npErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = None, \n",
    "                                         nonPromptSF=nonPromptSF + npErr,\n",
    "                                         nSteps = 50,                                         \n",
    "                                        )            \n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                npErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                npErr -= stepSize\n",
    "                trend=-1\n",
    "        nonPromptUp = npErr        \n",
    "        \n",
    "        return ttgSF, ttgammaUp, ttgammaDown, nonPromptSF, nonPromptUp, nonPromptDown, best_lk\n",
    "        \n",
    "    else:\n",
    "        return ttgSF, nonPromptSF, best_lk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = h.integrate('systematic','nominal').values()\n",
    "mcYield = []\n",
    "\n",
    "for i, sample in enumerate(grouping.keys()):\n",
    "    mcYield.append([])\n",
    "    for j, category in enumerate(groupingPho.keys()):\n",
    "        v = vals[(category,sample)]\n",
    "        mcYield[-1].append(v)\n",
    "mcYield = np.array(mcYield)\n",
    "\n",
    "errs = h.integrate('systematic','nominal')._sumw2\n",
    "\n",
    "mcYieldErr = []\n",
    "for s in errs:\n",
    "    mcYieldErr.append(errs[s]**0.5)\n",
    "\n",
    "mcYieldErr = np.array(mcYieldErr)\n",
    "mcYieldErr.shape = (3,6)\n",
    "mcYieldErr = mcYieldErr.transpose()\n",
    "\n",
    "misIDEleSF = MisIDSFResults['nominal']\n",
    "\n",
    "mcYield[:,1] *= misIDEleSF\n",
    "mcYieldErr[:,1] *= misIDEleSF\n",
    "\n",
    "\n",
    "fitData = {\n",
    "    'mcYield':mcYield, \n",
    "    'mcYieldErr':mcYieldErr,\n",
    "    'photonPurity':photonPurityResults['nominal'][0], \n",
    "    'photonPurityErr':photonPurityResults['nominal'][1],\n",
    "    'topPurity':topPurityResults['nominal'][0],\n",
    "    'topPurityErr':topPurityResults['nominal'][1], \n",
    "    'nData':nData, \n",
    "}\n",
    "\n",
    "output = maximizeLikelihood(fitData,\n",
    "                        nSteps=100, \n",
    "                        find1sigma=True, \n",
    "                        nStepsErr=100, \n",
    "                        startTTGamma=1,\n",
    "                        startNonprompt=1\n",
    "                       )\n",
    "bestTTGSF, bestTTGSF_Up, bestTTGSF_Down, bestNPSF, bestNPSF_Up, bestNPSF_Down, mxLk = output                                                                                                         \n",
    "print(\"TTGamma SF = %.4f +%.4f %.4f\"%(bestTTGSF, bestTTGSF_Up, bestTTGSF_Down))\n",
    "print(\"nonPrompt SF = %.4f +%.4f %.4f\"%(bestNPSF, bestNPSF_Up, bestNPSF_Down))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics = list(photonPurityResults.keys())\n",
    "systematics.remove('nominal')\n",
    "\n",
    "systResults = {}\n",
    "\n",
    "for syst in systematics:\n",
    "    vals = h.integrate('systematic',syst).values()\n",
    "    mcYield = []\n",
    "\n",
    "    for i, sample in enumerate(grouping.keys()):\n",
    "        mcYield.append([])\n",
    "        for j, category in enumerate(groupingPho.keys()):\n",
    "            v = vals[(category,sample)]\n",
    "            mcYield[-1].append(v)\n",
    "    mcYield = np.array(mcYield)\n",
    "\n",
    "    errs = h.integrate('systematic',syst)._sumw2\n",
    "\n",
    "    mcYieldErr = []\n",
    "    for s in errs:\n",
    "        mcYieldErr.append(errs[s]**0.5)\n",
    "\n",
    "    mcYieldErr = np.array(mcYieldErr)\n",
    "    mcYieldErr.shape = (3,6)\n",
    "    mcYieldErr = mcYieldErr.transpose()\n",
    "\n",
    "    misIDEleSF = MisIDSFResults[syst]\n",
    "\n",
    "    mcYield[:,1] *= misIDEleSF\n",
    "    mcYieldErr[:,1] *= misIDEleSF\n",
    "\n",
    "    \n",
    "    fitDataSyst = {\n",
    "        'mcYield':mcYield, \n",
    "        'mcYieldErr':mcYieldErr,\n",
    "        'photonPurity':photonPurityResults[syst][0], \n",
    "        'photonPurityErr':photonPurityResults[syst][1],\n",
    "        'topPurity':topPurityResults[syst][0],\n",
    "        'topPurityErr':topPurityResults[syst][1], \n",
    "        'nData':nData, \n",
    "    }\n",
    "    \n",
    "    output = maximizeLikelihood(fitDataSyst,\n",
    "                            nSteps=100, \n",
    "                            find1sigma=False, \n",
    "                            nStepsErr=100, \n",
    "                            startTTGamma=1,\n",
    "                            startNonprompt=1\n",
    "                           )\n",
    "    bestTTGSF, bestNPSF, bestLk = output\n",
    "    systResults[syst] = bestTTGSF\n",
    "\n",
    "print (systResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkVals = []\n",
    "ttgVals = np.arange(0,2.,.01)\n",
    "for ttgSF in ttgVals:\n",
    "    _ttg, _np, _lk = maximizeLikelihood(fitData, ttgSF = ttgSF, nSteps=50)\n",
    "    lkVals.append(-2*np.log(_lk/mxLk))\n",
    "\n",
    "lkVals = np.array(lkVals)\n",
    "\n",
    "plt.scatter(ttgVals[lkVals<6],lkVals[lkVals<6],color='blue')\n",
    "plt.scatter(ttgVals[lkVals<4],lkVals[lkVals<4],color='yellow')\n",
    "plt.scatter(ttgVals[lkVals<1],lkVals[lkVals<1],color='green')\n",
    "plt.ylabel(\"2*NLL\")\n",
    "plt.xlabel(\"$t\\overline{t}\\gamma$ SF\")\n",
    "\n",
    "ttgVals2Sig = ttgVals[lkVals<5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkVals = []\n",
    "npVals = np.arange(0,2.,.01)\n",
    "for npSF in npVals:\n",
    "    _ttg, _np, _lk = maximizeLikelihood(fitData, nonPromptSF= npSF, nSteps=50)\n",
    "    lkVals.append(-2*np.log(_lk/mxLk))\n",
    "\n",
    "lkVals = np.array(lkVals)\n",
    "\n",
    "plt.scatter(npVals[lkVals<6],lkVals[lkVals<6],color='blue')\n",
    "plt.scatter(npVals[lkVals<4],lkVals[lkVals<4],color='yellow')\n",
    "plt.scatter(npVals[lkVals<1],lkVals[lkVals<1],color='green')\n",
    "plt.ylabel(\"2*NLL\")\n",
    "plt.xlabel(\"Nonprompt SF\")\n",
    "\n",
    "npVals2Sig = npVals[lkVals<5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkVals = []\n",
    "for npSF in npVals2Sig:\n",
    "    _lkVals = []\n",
    "    for ttg in ttgVals2Sig:\n",
    "        _ttg, _np, _lk = maximizeLikelihood(fitData, ttgSF= ttg, nonPromptSF= npSF, nSteps=1)\n",
    "        _lkVals.append(-2*np.log(_lk/mxLk))\n",
    "    lkVals.append(_lkVals)\n",
    "lkVals = np.array(lkVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(ttgVals2Sig, npVals2Sig, lkVals, [0,1,4],colors=['green','yellow'])\n",
    "plt.plot(bestTTGSF, bestNPSF,marker='+',color='black',markersize=12,markeredgewidth=3);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
